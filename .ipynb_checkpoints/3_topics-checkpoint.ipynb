{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad57ce9",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "- Determine the topics in the conversations of chosen characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65016a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427c3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets = ['episode1', 'episode2', 'episode3', 'episode4', 'episode5', 'episode6']\n",
    "data = pd.concat([pd.read_excel('data.xlsx', sheet_name = sheet) for sheet in sheets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa95a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (data\n",
    "     .assign(dialogue=lambda df_: df_.dialogue.str.replace('\\s+', ' ', regex=True).str.strip())\n",
    "     .assign(sorted_pairs=lambda df_: df_.apply(lambda df_: '-'.join(sorted([df_['initiator'], df_['responder']])), axis=1))\n",
    "     .assign(weight=lambda df_: df_.groupby(['sorted_pairs'])['sorted_pairs'].transform('count'))\n",
    "     .assign(dialogue=lambda df_: df_.groupby(['sorted_pairs'])['dialogue'].transform(lambda df_: ' '.join(df_.unique())))\n",
    "     .drop_duplicates('sorted_pairs')\n",
    "     .drop(columns='sorted_pairs')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1ed6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# func to add topics\n",
    "def add_topic_labels(df):\n",
    "    # create a list of documents from the 'script' column\n",
    "    documents = list(df['dialogue'])\n",
    "\n",
    "    # define stop words, tags to remove, and words to remove\n",
    "    stop_words = stopwords.words('english')\n",
    "    removal = ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n",
    "    remove_words = ['like','gone','know','right','na','gon','yeah','really','okay','even','sure','miller','lisa',\n",
    "                    'get','gonna','well','thank','oh','uh','hi','got','um','go','little','mortimer','mayfield','though',\n",
    "                    'would','great','come','hey','wanna','hmm','mr','yes','good','give','jorgy','coleman','ruth','also',\n",
    "                    'going','want','let','think','one','us','look','make','ed','gotta','ben','dale','randolph','actually',\n",
    "                    'something','back','see','need','man','say','sorry','could','madoff','wrong','eric','robert','saw',\n",
    "                    'thing','lt','lf','made','way','said','sir','two','new','naomi','ha','ok','around','jean','ron','mm','onto',\n",
    "                    'louis','winthorpe','gekko','gordon','buddy','jordan','tell','erin','sam','eric','seen','michael','seth',\n",
    "                    'patrick','paul','allen','listen','god','bateman','marcus','heh','bernie','big','steve','jimmy','mrs',\n",
    "                    'anything','christie','patrick','dorsia','garfield','mark','maybe','nick','donnie','name','went'\n",
    "                   ]\n",
    "\n",
    "    # remove stop words and unwanted words\n",
    "    tokenized_docs = [[token for token in gensim.utils.simple_preprocess(doc) if token not in stop_words and token not in remove_words] for doc in documents]\n",
    "\n",
    "    # remove tags\n",
    "    tagged_docs = [nltk.pos_tag(doc) for doc in tokenized_docs]\n",
    "    tokenized_docs = [[token for token, pos in doc if pos not in removal] for doc in tagged_docs]\n",
    "\n",
    "    # create a dictionary from the tokenized documents\n",
    "    dictionary = corpora.Dictionary(tokenized_docs)\n",
    "\n",
    "    # create a bag-of-words representation of the documents\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "    # train an LDA model on the corpus\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                id2word=dictionary,\n",
    "                                                num_topics=5,\n",
    "                                                random_state=42,\n",
    "                                                passes=10)\n",
    "\n",
    "    # extract the top fifteen words for each topic\n",
    "    topic_labels = []\n",
    "    for doc in tokenized_docs:\n",
    "        bow = dictionary.doc2bow(doc)\n",
    "        topics = lda_model.get_document_topics(bow)\n",
    "        top_fifteen_words = [dictionary[word] for word, prob in sorted(lda_model.get_topic_terms(max(topics, key=lambda x: x[1])[0], topn=15), key=lambda x: x[1], reverse=True)]\n",
    "        topic_labels.append(top_fifteen_words)\n",
    "\n",
    "    # add the topic labels as a new column in the dataframe\n",
    "    df['topic'] = topic_labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d57ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the names to create DataFrames for\n",
    "chosen_names = ['NICOLE', 'TANYA', 'RACHEL', 'SHANE', 'ARMOND', 'PAULA', 'OLIVIA']\n",
    "\n",
    "# Loop through the chosen names and create a new DataFrame for each one\n",
    "for name in chosen_names:\n",
    "    # Select rows where the name appears in either initiator or responder\n",
    "    new_df = df[(df['initiator'] == name) | (df['responder'] == name)]\n",
    "    \n",
    "    # Create a new DataFrame with the selected rows\n",
    "    globals()[f'{name}_df'] = pd.DataFrame(new_df)\n",
    "    \n",
    "# func to add word_count column\n",
    "def tweak_df(df):\n",
    "    return (df\n",
    "             .assign(word_count=lambda df_: df_.dialogue.str.len().astype('int16'))\n",
    "             .astype({'weight': 'int8'})\n",
    "             .sort_values('word_count', ascending=False)\n",
    "             .reset_index()\n",
    "             .drop(columns='index')\n",
    "            )\n",
    "\n",
    "# list of dataframes to tweak\n",
    "tweak_these = [NICOLE_df, TANYA_df, RACHEL_df, SHANE_df, ARMOND_df, PAULA_df, OLIVIA_df]\n",
    "\n",
    "for i in range(len(tweak_these)):\n",
    "    tweak_these[i] = tweak_df(tweak_these[i])\n",
    "\n",
    "NICOLE_df, TANYA_df, RACHEL_df, SHANE_df, ARMOND_df, PAULA_df, OLIVIA_df = tweak_these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "281f35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NICOLE\n",
    "# create mapping to create dataframe for each movie\n",
    "characters = {'NICOLE_OLIVIA':0, 'NICOLE_MARK':1, 'RACHEL_NICOLE':2}\n",
    "\n",
    "# loop through dictionary to create dataframes\n",
    "for key, value in characters.items():\n",
    "    NICOLE_df_key = pd.DataFrame([[NICOLE_df.loc[value, 'initiator'], NICOLE_df.loc[value, 'responder'], NICOLE_df.loc[value, 'dialogue']]], columns=['initiator', 'responder', 'dialogue']).pipe(add_topic_labels)\n",
    "    globals()[key] = NICOLE_df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80692e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TANYA\n",
    "# create mapping to create dataframe for each movie\n",
    "characters = {'TANYA_BELINDA':0, 'GREG_TANYA':1, 'TANYA_SHANE':2}\n",
    "\n",
    "# loop through dictionary to create dataframes\n",
    "for key, value in characters.items():\n",
    "    TANYA_df_key = pd.DataFrame([[TANYA_df.loc[value, 'initiator'], TANYA_df.loc[value, 'responder'], TANYA_df.loc[value, 'dialogue']]], columns=['initiator', 'responder', 'dialogue']).pipe(add_topic_labels)\n",
    "    globals()[key] = TANYA_df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c626a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RACHEL\n",
    "# create mapping to create dataframe for each movie\n",
    "characters = {'RACHEL_SHANE':0, 'KITTY_RACHEL':1, 'BELINDA_RACHEL':6}\n",
    "\n",
    "# loop through dictionary to create dataframes\n",
    "for key, value in characters.items():\n",
    "    RACHEL_df_key = pd.DataFrame([[RACHEL_df.loc[value, 'initiator'], RACHEL_df.loc[value, 'responder'], RACHEL_df.loc[value, 'dialogue']]], columns=['initiator', 'responder', 'dialogue']).pipe(add_topic_labels)\n",
    "    globals()[key] = RACHEL_df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43b7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SHANE\n",
    "# create mapping to create dataframe for each movie\n",
    "characters = {'ARMOND_SHANE':1, 'SHANE_KITTY':2, 'SHANE_OLIVIA':5}\n",
    "\n",
    "# loop through dictionary to create dataframes\n",
    "for key, value in characters.items():\n",
    "    SHANE_df_key = pd.DataFrame([[SHANE_df.loc[value, 'initiator'], SHANE_df.loc[value, 'responder'], SHANE_df.loc[value, 'dialogue']]], columns=['initiator', 'responder', 'dialogue']).pipe(add_topic_labels)\n",
    "    globals()[key] = SHANE_df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0519632",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ARMOND\n",
    "# create mapping to create dataframe for each movie\n",
    "characters = {'ARMOND_MARK':1, 'ARMOND_DILLON':2, 'ARMOND_LANI':3}\n",
    "\n",
    "# loop through dictionary to create dataframes\n",
    "for key, value in characters.items():\n",
    "    ARMOND_df_key = pd.DataFrame([[ARMOND_df.loc[value, 'initiator'], ARMOND_df.loc[value, 'responder'], ARMOND_df.loc[value, 'dialogue']]], columns=['initiator', 'responder', 'dialogue']).pipe(add_topic_labels)\n",
    "    globals()[key] = ARMOND_df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c869b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PAULA\n",
    "# create mapping to create dataframe for each movie\n",
    "characters = {'OLIVIA_PAULA':0, 'PAULA_KAI':1, 'MARK_PAULA':4}\n",
    "\n",
    "# loop through dictionary to create dataframes\n",
    "for key, value in characters.items():\n",
    "    PAULA_df_key = pd.DataFrame([[PAULA_df.loc[value, 'initiator'], PAULA_df.loc[value, 'responder'], PAULA_df.loc[value, 'dialogue']]], columns=['initiator', 'responder', 'dialogue']).pipe(add_topic_labels)\n",
    "    globals()[key] = PAULA_df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c217be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLIVIA\n",
    "# create mapping to create dataframe for each movie\n",
    "characters = {'MARK_OLIVIA':2, 'TANYA_OLIVIA':3, 'OLIVIA_QUINN':6}\n",
    "\n",
    "# loop through dictionary to create dataframes\n",
    "for key, value in characters.items():\n",
    "    OLIVIA_df_key = pd.DataFrame([[OLIVIA_df.loc[value, 'initiator'], OLIVIA_df.loc[value, 'responder'], OLIVIA_df.loc[value, 'dialogue']]], columns=['initiator', 'responder', 'dialogue']).pipe(add_topic_labels)\n",
    "    globals()[key] = OLIVIA_df_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a67210cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dataframes\n",
    "dataframes = [MARK_OLIVIA, TANYA_OLIVIA, OLIVIA_QUINN, OLIVIA_PAULA, PAULA_KAI, MARK_PAULA,\n",
    "              ARMOND_MARK, ARMOND_DILLON, ARMOND_LANI, ARMOND_SHANE, SHANE_KITTY, SHANE_OLIVIA,\n",
    "              RACHEL_SHANE, KITTY_RACHEL, BELINDA_RACHEL, TANYA_BELINDA, GREG_TANYA, TANYA_SHANE,\n",
    "              NICOLE_OLIVIA, NICOLE_MARK, RACHEL_NICOLE\n",
    "             ]\n",
    "\n",
    "\n",
    "# Initialize an empty dataframe to store the concatenated data\n",
    "conv_df = pd.DataFrame()\n",
    "\n",
    "# Concatenate the dataframes vertically\n",
    "for df in dataframes:\n",
    "    conv_df = pd.concat([conv_df, df], axis=0)\n",
    "\n",
    "# Reset the index of the concatenated dataframe\n",
    "conv_df = conv_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c297939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initiator</th>\n",
       "      <th>responder</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARK</td>\n",
       "      <td>OLIVIA</td>\n",
       "      <td>Morning, ladies. What? Dad, what the hell are ...</td>\n",
       "      <td>[dad, mean, paula, narrative, feel, woman, yet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TANYA</td>\n",
       "      <td>OLIVIA</td>\n",
       "      <td>Hey. Hi, girls. Hello! Hi. Hey. Hi. -How are y...</td>\n",
       "      <td>[girls, ocean, beach, skin, gosh, day, left, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OLIVIA</td>\n",
       "      <td>QUINN</td>\n",
       "      <td>Quinn, what are you doing in there? Are you fa...</td>\n",
       "      <td>[phone, quinn, whatever, addicted, fucking, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OLIVIA</td>\n",
       "      <td>PAULA</td>\n",
       "      <td>Oh my God, who are these people? So, these two...</td>\n",
       "      <td>[guy, fuck, paula, shit, cause, bad, everythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAULA</td>\n",
       "      <td>KAI</td>\n",
       "      <td>It is so beautiful. When I was younger, my fat...</td>\n",
       "      <td>[people, paula, stole, brothers, shit, help, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MARK</td>\n",
       "      <td>PAULA</td>\n",
       "      <td>Don’t you think? Yeah. Yeah. Yeah, what– what ...</td>\n",
       "      <td>[paula, question, stand, old, balls, swollen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ARMOND</td>\n",
       "      <td>MARK</td>\n",
       "      <td>Oh, Mr.. How can I help you? Uh, my son and I ...</td>\n",
       "      <td>[gay, enjoy, mossbacher, tonight, sign, course...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ARMOND</td>\n",
       "      <td>DILLON</td>\n",
       "      <td>What? What is it? Um, Lani is in your office, ...</td>\n",
       "      <td>[fuck, baby, shit, dillon, talk, office, train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ARMOND</td>\n",
       "      <td>LANI</td>\n",
       "      <td>Here they come. Wave, Lani. There we are. Wave...</td>\n",
       "      <td>[lani, room, tuna, mean, day, always, baby, pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ARMOND</td>\n",
       "      <td>SHANE</td>\n",
       "      <td>Oh, Mr. Patton and Ms. Undecided. You finding ...</td>\n",
       "      <td>[room, suite, pineapple, mother, pool, boat, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SHANE</td>\n",
       "      <td>KITTY</td>\n",
       "      <td>Honey? Hi. Hey, Mom. What’s up? Okay, so the s...</td>\n",
       "      <td>[mom, love, shane, room, happy, nice, cathy, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SHANE</td>\n",
       "      <td>OLIVIA</td>\n",
       "      <td>Hey. So, yesterday you were reading Freud and ...</td>\n",
       "      <td>[reading, nietzsche, freud, pool, water, book,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RACHEL</td>\n",
       "      <td>SHANE</td>\n",
       "      <td>Oh, there’s a lobster bake tonight. Oh. Lobste...</td>\n",
       "      <td>[shane, room, honeymoon, mean, fucking, wife, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KITTY</td>\n",
       "      <td>RACHEL</td>\n",
       "      <td>Surprise! Oh, my God. Look at her face, poor t...</td>\n",
       "      <td>[money, happy, rachel, nice, cathy, love, make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ARMOND</td>\n",
       "      <td>RACHEL</td>\n",
       "      <td>I’m presuming Mr. Shane and Mrs. Rachel? Oh! T...</td>\n",
       "      <td>[aloha, suite, thanks, bye, palm, correct, pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TANYA</td>\n",
       "      <td>BELINDA</td>\n",
       "      <td>Oh, no. I just… Really? Are you sure? I would ...</td>\n",
       "      <td>[mother, mean, love, dinner, tanya, belinda, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GREG</td>\n",
       "      <td>TANYA</td>\n",
       "      <td>Excuse me. I think this is my room. Oh, crap. ...</td>\n",
       "      <td>[greg, dead, blm, fuck, mean, fun, hang, take,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TANYA</td>\n",
       "      <td>SHANE</td>\n",
       "      <td>Hey, everybody. Hey! Hey. Thank you for coming...</td>\n",
       "      <td>[mother, poor, wanted, box, cruel, open, every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NICOLE</td>\n",
       "      <td>OLIVIA</td>\n",
       "      <td>Hey, girls. What, Mom? Liv, come up front. I t...</td>\n",
       "      <td>[mom, olivia, girls, paula, whatever, fine, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NICOLE</td>\n",
       "      <td>MARK</td>\n",
       "      <td>I, uh… Are they bigger? I don’t know, you tell...</td>\n",
       "      <td>[nic, mean, cancer, lot, told, tomorrow, talk,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RACHEL</td>\n",
       "      <td>NICOLE</td>\n",
       "      <td>Sorry, am I interrupting? Uh, it’s fine. Hi. H...</td>\n",
       "      <td>[mean, career, women, vacation, rachel, piece,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initiator responder                                           dialogue  \\\n",
       "0       MARK    OLIVIA  Morning, ladies. What? Dad, what the hell are ...   \n",
       "1      TANYA    OLIVIA  Hey. Hi, girls. Hello! Hi. Hey. Hi. -How are y...   \n",
       "2     OLIVIA     QUINN  Quinn, what are you doing in there? Are you fa...   \n",
       "3     OLIVIA     PAULA  Oh my God, who are these people? So, these two...   \n",
       "4      PAULA       KAI  It is so beautiful. When I was younger, my fat...   \n",
       "5       MARK     PAULA  Don’t you think? Yeah. Yeah. Yeah, what– what ...   \n",
       "6     ARMOND      MARK  Oh, Mr.. How can I help you? Uh, my son and I ...   \n",
       "7     ARMOND    DILLON  What? What is it? Um, Lani is in your office, ...   \n",
       "8     ARMOND      LANI  Here they come. Wave, Lani. There we are. Wave...   \n",
       "9     ARMOND     SHANE  Oh, Mr. Patton and Ms. Undecided. You finding ...   \n",
       "10     SHANE     KITTY  Honey? Hi. Hey, Mom. What’s up? Okay, so the s...   \n",
       "11     SHANE    OLIVIA  Hey. So, yesterday you were reading Freud and ...   \n",
       "12    RACHEL     SHANE  Oh, there’s a lobster bake tonight. Oh. Lobste...   \n",
       "13     KITTY    RACHEL  Surprise! Oh, my God. Look at her face, poor t...   \n",
       "14    ARMOND    RACHEL  I’m presuming Mr. Shane and Mrs. Rachel? Oh! T...   \n",
       "15     TANYA   BELINDA  Oh, no. I just… Really? Are you sure? I would ...   \n",
       "16      GREG     TANYA  Excuse me. I think this is my room. Oh, crap. ...   \n",
       "17     TANYA     SHANE  Hey, everybody. Hey! Hey. Thank you for coming...   \n",
       "18    NICOLE    OLIVIA  Hey, girls. What, Mom? Liv, come up front. I t...   \n",
       "19    NICOLE      MARK  I, uh… Are they bigger? I don’t know, you tell...   \n",
       "20    RACHEL    NICOLE  Sorry, am I interrupting? Uh, it’s fine. Hi. H...   \n",
       "\n",
       "                                                topic  \n",
       "0   [dad, mean, paula, narrative, feel, woman, yet...  \n",
       "1   [girls, ocean, beach, skin, gosh, day, left, a...  \n",
       "2   [phone, quinn, whatever, addicted, fucking, li...  \n",
       "3   [guy, fuck, paula, shit, cause, bad, everythin...  \n",
       "4   [people, paula, stole, brothers, shit, help, f...  \n",
       "5   [paula, question, stand, old, balls, swollen, ...  \n",
       "6   [gay, enjoy, mossbacher, tonight, sign, course...  \n",
       "7   [fuck, baby, shit, dillon, talk, office, train...  \n",
       "8   [lani, room, tuna, mean, day, always, baby, pi...  \n",
       "9   [room, suite, pineapple, mother, pool, boat, d...  \n",
       "10  [mom, love, shane, room, happy, nice, cathy, l...  \n",
       "11  [reading, nietzsche, freud, pool, water, book,...  \n",
       "12  [shane, room, honeymoon, mean, fucking, wife, ...  \n",
       "13  [money, happy, rachel, nice, cathy, love, make...  \n",
       "14  [aloha, suite, thanks, bye, palm, correct, pre...  \n",
       "15  [mother, mean, love, dinner, tanya, belinda, p...  \n",
       "16  [greg, dead, blm, fuck, mean, fun, hang, take,...  \n",
       "17  [mother, poor, wanted, box, cruel, open, every...  \n",
       "18  [mom, olivia, girls, paula, whatever, fine, hi...  \n",
       "19  [nic, mean, cancer, lot, told, tomorrow, talk,...  \n",
       "20  [mean, career, women, vacation, rachel, piece,...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bbf0aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dad',\n",
       "  'mean',\n",
       "  'paula',\n",
       "  'narrative',\n",
       "  'feel',\n",
       "  'woman',\n",
       "  'yet',\n",
       "  'worry',\n",
       "  'mother',\n",
       "  'center',\n",
       "  'vacation',\n",
       "  'please',\n",
       "  'waterboard',\n",
       "  'thought',\n",
       "  'dance']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv_df.loc[0, ['topic']].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef1b8d9",
   "metadata": {},
   "source": [
    "## Topic conversations of interesting characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ef837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rcParams\n",
    "\n",
    "\n",
    "# SET VIZ TEMPLATE\n",
    "# colors\n",
    "YELLOW='yellow'\n",
    "BLACK='#1a1a1a'\n",
    "GREY='#696969'\n",
    "WHITE='white'\n",
    "\n",
    "# fonts\n",
    "futura_font_path = 'graphfonts/Futura/futura-medium-condensed.ttf'\n",
    "FUTURA = fm.FontProperties(fname=futura_font_path)\n",
    "\n",
    "paypal_font_path = 'graphfonts/Paypal/PayPalSansSmall-Regular.ttf'\n",
    "PAYPAL = fm.FontProperties(fname=paypal_font_path)\n",
    "\n",
    "DPI=200\n",
    "\n",
    "#func to plot topics\n",
    "def plot_word_grid(words, suptitle):\n",
    "    # Define the figure size and background color\n",
    "    fig = plt.figure(figsize=(8, 4), facecolor=BLACK, dpi=DPI)\n",
    "\n",
    "    # Set the title\n",
    "    fig.suptitle(suptitle, fontproperties=FUTURA, color='white', fontsize=12, y=.93)\n",
    "\n",
    "    # Define the layout of the subplots\n",
    "    layout = (5, 5)\n",
    "\n",
    "    # Create subplots and add words to them\n",
    "    for i, word in enumerate(words):\n",
    "        ax = fig.add_subplot(*layout, i+1)\n",
    "        ax.set_facecolor(BLACK)\n",
    "        ax.text(0.5, 0.5, word, fontsize=10, ha='center', va='center', fontproperties=PAYPAL, color=YELLOW)\n",
    "\n",
    "        # Remove spines and tick labels\n",
    "        for side in 'top,right,bottom,left'.split(','):\n",
    "            ax.spines[side].set_visible(False)\n",
    "        ax.tick_params(axis='both', which='both', length=0)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "    \n",
    "    # Show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df19074",
   "metadata": {},
   "source": [
    "### NICOLE'S conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(RACHEL_NICOLE.loc[0, 'topic'], 'NICOLE and OLIVIA conversation topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(NICOLE_df.loc[1, 'topic'], 'NICOLE and MARK conversation topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(NICOLE_df.loc[2, 'topic'], 'NICOLE and RACHEL conversation topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e465e8",
   "metadata": {},
   "source": [
    "### TANYA'S conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56343869",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(TANYA_df.loc[0, 'topic'], 'TANYA and BELINDA conversation topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(TANYA_df.loc[1, 'topic'], 'GREG and TANYA conversation topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(TANYA_df.loc[2, 'topic'], 'TANYA and SHANE conversation topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced486f",
   "metadata": {},
   "source": [
    "### RACHEL'S conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(RACHEL_df.loc[0, 'topic'], 'RACHEL and SHANE conversation topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(RACHEL_df.loc[3, 'topic'], 'RACHEL and MARK conversation topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ebe109",
   "metadata": {},
   "source": [
    "### SHANE'S conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b79166",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(SHANE_df.loc[1, 'topic'], 'SHANE and ARMOND conversation topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364de5fb",
   "metadata": {},
   "source": [
    "### ARMOND'S conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(ARMOND_df.loc[1, 'topic'], 'ARMOND and MARK conversation topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21536474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(ARMOND_df.loc[2, 'topic'], 'ARMOND and DILLON conversation topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a3f81",
   "metadata": {},
   "source": [
    "### PAULA'S conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(PAULA_df.loc[0, 'topic'], 'PAULA and OLIVIA conversation topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(PAULA_df.loc[6, 'topic'], 'PAULA and ARMOND conversation topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e48f72",
   "metadata": {},
   "source": [
    "### OLIVIA'S Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa64e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(OLIVIA_df.loc[7, 'topic'], 'OLIVIA and SHANE conversation topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_grid(OLIVIA_df.loc[6, 'topic'], 'OLIVIA and QUINN conversation topics')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
