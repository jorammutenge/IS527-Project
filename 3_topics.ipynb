{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65016a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427c3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheets = ['episode1', 'episode2', 'episode3', 'episode4', 'episode5', 'episode6']\n",
    "data = pd.concat([pd.read_excel('data.xlsx', sheet_name = sheet) for sheet in sheets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2409ff1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initiator</th>\n",
       "      <th>responder</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>word_count</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PASSENGER 1</td>\n",
       "      <td>SHANE</td>\n",
       "      <td>You headed home? Yeah We were at the Amanari. ...</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLIVIA</td>\n",
       "      <td>PAULA</td>\n",
       "      <td>Oh my God, who are these people? So, these two...</td>\n",
       "      <td>119</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NICOLE</td>\n",
       "      <td>OLIVIA</td>\n",
       "      <td>Hey, girls. What, Mom? Liv, come up front. I t...</td>\n",
       "      <td>20</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARMOND</td>\n",
       "      <td>LANI</td>\n",
       "      <td>Here they come. Wave, Lani. There we are. Wave...</td>\n",
       "      <td>199</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BELINDA</td>\n",
       "      <td>NICOLE</td>\n",
       "      <td>Welcome. Thank you. Of course, yeah.</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>HOTEL GUEST</td>\n",
       "      <td>TANYA</td>\n",
       "      <td>How’s it going? It’s hot today. What’s good? M...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>NICOLE</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>We are so lucky to be here all together as a f...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>ARMOND</td>\n",
       "      <td>John, how are you? Yes. Okay, well– All right,...</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SHANE</td>\n",
       "      <td>BARTENDER</td>\n",
       "      <td>Double tequila. Sure, sounds good. Coming righ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>SHANE</td>\n",
       "      <td>RECEPTIONIST</td>\n",
       "      <td>Yeah, I have a message. She got her own room. ...</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       initiator     responder  \\\n",
       "0    PASSENGER 1         SHANE   \n",
       "1         OLIVIA         PAULA   \n",
       "2         NICOLE        OLIVIA   \n",
       "3         ARMOND          LANI   \n",
       "4        BELINDA        NICOLE   \n",
       "..           ...           ...   \n",
       "55   HOTEL GUEST         TANYA   \n",
       "64        NICOLE        FAMILY   \n",
       "68          JOHN        ARMOND   \n",
       "98         SHANE     BARTENDER   \n",
       "104        SHANE  RECEPTIONIST   \n",
       "\n",
       "                                              dialogue  word_count  weight  \n",
       "0    You headed home? Yeah We were at the Amanari. ...         105       1  \n",
       "1    Oh my God, who are these people? So, these two...         119      31  \n",
       "2    Hey, girls. What, Mom? Liv, come up front. I t...          20      57  \n",
       "3    Here they come. Wave, Lani. There we are. Wave...         199       6  \n",
       "4                 Welcome. Thank you. Of course, yeah.           3       2  \n",
       "..                                                 ...         ...     ...  \n",
       "55   How’s it going? It’s hot today. What’s good? M...          21       1  \n",
       "64   We are so lucky to be here all together as a f...          12       1  \n",
       "68   John, how are you? Yes. Okay, well– All right,...          45       1  \n",
       "98   Double tequila. Sure, sounds good. Coming righ...           8       1  \n",
       "104  Yeah, I have a message. She got her own room. ...          87       1  \n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data\n",
    " .assign(dialogue=lambda df_: df_.dialogue.str.replace('\\s+', ' ', regex=True).str.strip())\n",
    " .assign(word_count=lambda df_: df_.dialogue.str.split().str.len())\n",
    " .assign(dialogue=lambda df_: df_.dialogue.apply(lambda df_: df_.strip()))\n",
    " .assign(sorted_pairs=lambda df_: df_.apply(lambda df_: '-'.join(sorted([df_['initiator'], df_['responder']])), axis=1))\n",
    " .assign(weight=lambda df_: df_.groupby(['sorted_pairs'])['sorted_pairs'].transform('count'))\n",
    " .assign(dialogue=lambda df_: df_.groupby(['sorted_pairs'])['dialogue'].transform(lambda df_: ' '.join(df_.unique())))\n",
    " .drop_duplicates('sorted_pairs')\n",
    " .drop(columns='sorted_pairs')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1545c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0812af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# create a list of documents from the 'dialogue' column\n",
    "documents = list(df['dialogue'])\n",
    "\n",
    "# define stop words, tags to remove, and words to remove\n",
    "stop_words = stopwords.words('english')\n",
    "removal = ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n",
    "remove_words = ['like', 'gone', 'know', 'right', 'na', 'gon', 'yeah', 'really', 'okay',\n",
    "                'get', 'gonna', 'well', 'thank', 'oh', 'uh', 'hi', 'got', 'um', 'go',\n",
    "                'would', 'great', 'come', 'hey', 'wanna', 'hmm', 'mr', 'yes', 'good']\n",
    "\n",
    "# remove stop words and unwanted words\n",
    "tokenized_docs = [[token for token in gensim.utils.simple_preprocess(doc) if token not in stop_words and token not in remove_words] for doc in documents]\n",
    "\n",
    "# remove tags\n",
    "tagged_docs = [nltk.pos_tag(doc) for doc in tokenized_docs]\n",
    "tokenized_docs = [[token for token, pos in doc if pos not in removal] for doc in tagged_docs]\n",
    "\n",
    "# create a dictionary from the tokenized documents\n",
    "dictionary = corpora.Dictionary(tokenized_docs)\n",
    "\n",
    "# create a bag-of-words representation of the documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "# train an LDA model on the corpus\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=5,\n",
    "                                            random_state=42,\n",
    "                                            passes=10)\n",
    "\n",
    "# extract the top fifteen words for each topic\n",
    "topic_labels = []\n",
    "for doc in tokenized_docs:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    top_fifteen_words = [dictionary[word] for word, prob in sorted(lda_model.get_topic_terms(max(topics, key=lambda x: x[1])[0], topn=15), key=lambda x: x[1], reverse=True)]\n",
    "    topic_labels.append(top_fifteen_words)\n",
    "\n",
    "# add the topic labels as a new column in the dataframe\n",
    "df['topic'] = topic_labels\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[64, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d57ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the names to create DataFrames for\n",
    "chosen_names = ['NICOLE', 'TANYA', 'RACHEL', 'SHANE', 'ARMOND', 'PAUL', 'OLIVIA']\n",
    "\n",
    "# Loop through the chosen names and create a new DataFrame for each one\n",
    "for name in chosen_names:\n",
    "    # Select rows where the name appears in either initiator or responder\n",
    "    new_df = df[(df['initiator'] == name) | (df['responder'] == name)]\n",
    "    \n",
    "    # Create a new DataFrame with the selected rows\n",
    "    globals()[f'{name}_df'] = pd.DataFrame(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "NICOLE_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "TANYA_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
